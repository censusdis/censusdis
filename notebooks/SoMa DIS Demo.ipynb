{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d69243fb-ad82-4991-b53d-a132a0dc49e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(1, os.path.join(os.getcwd(), os.pardir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4db388e7-b8c0-40db-b0b2-fe7efb272267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import censusdis.redistricting as crd\n",
    "\n",
    "from censusdis.states import STATE_NJ\n",
    "\n",
    "import divintseg as dis\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26726e4-0f9b-4279-8796-e1d41c4e7ad4",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook, we will demonstrate how to use the [`censusdis`](https://github.com/vengroff/censusdis) package \n",
    "to download some US Census data and then how to use the [`divintseg`](https://github.com/vengroff/divintseg) package \n",
    "to compute some diversity and integration metrics.\n",
    "\n",
    "In this example, we will look at data from the towns of South Orange\n",
    "and Maplewood (collectively known as SoMa) in Essex County,\n",
    "NJ. \n",
    "\n",
    "Once you are familiar with the API and how to use it, you can easily experiment with\n",
    "similar analysis of the area where you live."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3ba359-c801-4204-9119-c38a55a69fb4",
   "metadata": {},
   "source": [
    "## US Census API Key\n",
    "\n",
    "The US Census API uses a key to identify callers. If you don't already have a key, you can request\n",
    "one [here](https://api.census.gov/data/key_signup.html). Please put your key into this cell before \n",
    "running the notebook.\n",
    "\n",
    "For small queries like in this demo notebook, the API seems to work without a key, so you can leave\n",
    "it set to `None`, but for more serious work you will want to obtain a key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acdb3919-75a7-46f2-81da-68771578a181",
   "metadata": {},
   "outputs": [],
   "source": [
    "CENSUS_API_KEY=None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15466142-5f76-47ae-87e2-9a7f1dbe8d4b",
   "metadata": {},
   "source": [
    "## Basic Configuration\n",
    "\n",
    "### Year\n",
    "\n",
    "We can choose which census year we want to look at, 2000, 2010, or 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b191c8c-1f3c-487f-8738-47891d0429d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR = 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf2fe4d-f669-4a41-a5d8-47766907b34d",
   "metadata": {},
   "source": [
    "### Field Group\n",
    "\n",
    "A field group is a set of fields that the US Census uses to provide data\n",
    "in the various data sets it publishes. These groups cover all kinds of\n",
    "topics. We are interested in demographics and we are going to be using\n",
    "redistricting data, so the field groups available are those summarized \n",
    "[here](https://api.census.gov/data/2020/dec/pl/groups.html). Don't worry\n",
    "if nothing on that page means anything to you right now. We'll explain it\n",
    "here.\n",
    "\n",
    "If we choose P1, then the data is grouped purely based on race, \n",
    "not taking ethnicity into account at all. If we choose P2, then the data is\n",
    "first grouped by ethnicity, with people reporting Hispanic or Latino ethinicity\n",
    "put into one group regardless of their race. Everyone else is then divided into\n",
    "groups based on their race.\n",
    "\n",
    "Thus, P2 has one group that P1 does not have, which is Hispanic or Latino of \n",
    "any race. In the P1 data set, people who are in the Hispanic or Latino group \n",
    "in P2 are instead classified into one of the race-based groups. \n",
    "\n",
    "For more information, including additional options P3 and P4, see this\n",
    "additional \n",
    "[documentation](https://www.census.gov/programs-surveys/decennial-census/about/rdo/summary-files.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0ddb3ac-bbcc-4ffe-b127-78f6b506743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIELD_GROUP = 'P2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce50c382-8049-4932-9385-f69325750721",
   "metadata": {},
   "source": [
    "### Fields\n",
    "\n",
    "Since the specific fields that exist within a field group vary by year,\n",
    "we have to make a metadata query to find out what they are. This is a\n",
    "simple one-liner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01d136b0-ca6b-40bb-9db5-5c53a34d08ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "field_names, total_field, fields_by_race = crd.metadata(YEAR, FIELD_GROUP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1664e3b2-dfe1-471a-99ad-87f58ffeb9de",
   "metadata": {},
   "source": [
    "Each of the fields has a name (in `field_names`), and the API also groups them into \n",
    "racial groups (in `fields by race`) in case we want to use that for additional \n",
    "analysis. \n",
    "\n",
    "For the work we are doing here, we are just going to pass some of this metadata\n",
    "on to our data query. But we will take a quick look just to see the richness of the\n",
    "data provided by the census for people who are multiracial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8d6cfd7-568d-4df4-a320-537bcb077684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P2_070N': 'White; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
       " 'P2_071N': 'Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
       " 'P2_073N': 'White; Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
       " 'P2_060N': 'Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
       " 'P2_030N': 'White; Black or African American; Asian',\n",
       " 'P2_054N': 'White; Black or African American; Asian; Some Other Race',\n",
       " 'P2_042N': 'Black or African American; Asian; Native Hawaiian and Other Pacific Islander',\n",
       " 'P2_066N': 'White; Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
       " 'P2_043N': 'Black or African American; Asian; Some Other Race',\n",
       " 'P2_031N': 'White; Black or African American; Native Hawaiian and Other Pacific Islander',\n",
       " 'P2_067N': 'White; Black or African American; American Indian and Alaska Native; Asian; Some Other Race',\n",
       " 'P2_055N': 'White; Black or African American; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
       " 'P2_032N': 'White; Black or African American; Some Other Race',\n",
       " 'P2_020N': 'Black or African American; Native Hawaiian and Other Pacific Islander',\n",
       " 'P2_056N': 'White; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
       " 'P2_044N': 'Black or African American; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
       " 'P2_068N': 'White; Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
       " 'P2_021N': 'Black or African American; Some Other Race',\n",
       " 'P2_045N': 'American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
       " 'P2_033N': 'White; American Indian and Alaska Native; Asian',\n",
       " 'P2_069N': 'White; Black or African American; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
       " 'P2_057N': 'White; American Indian and Alaska Native; Asian; Some Other Race',\n",
       " 'P2_062N': 'Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
       " 'P2_061N': 'Black or African American; American Indian and Alaska Native; Asian; Some Other Race',\n",
       " 'P2_063N': 'Black or African American; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
       " 'P2_051N': 'White; Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
       " 'P2_050N': 'White; Black or African American; American Indian and Alaska Native; Asian',\n",
       " 'P2_052N': 'White; Black or African American; American Indian and Alaska Native; Some Other Race',\n",
       " 'P2_040N': 'Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
       " 'P2_064N': 'American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
       " 'P2_041N': 'Black or African American; American Indian and Alaska Native; Some Other Race',\n",
       " 'P2_053N': 'White; Black or African American; Asian; Native Hawaiian and Other Pacific Islander',\n",
       " 'P2_038N': 'White; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
       " 'P2_026N': 'Asian; Some Other Race',\n",
       " 'P2_014N': 'White; American Indian and Alaska Native',\n",
       " 'P2_002N': 'Hispanic or Latino',\n",
       " 'P2_027N': 'Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
       " 'P2_015N': 'White; Asian',\n",
       " 'P2_039N': 'Black or African American; American Indian and Alaska Native; Asian',\n",
       " 'P2_016N': 'White; Native Hawaiian and Other Pacific Islander',\n",
       " 'P2_005N': 'White alone',\n",
       " 'P2_029N': 'White; Black or African American; American Indian and Alaska Native',\n",
       " 'P2_017N': 'White; Some Other Race',\n",
       " 'P2_010N': 'Some Other Race alone',\n",
       " 'P2_034N': 'White; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
       " 'P2_022N': 'American Indian and Alaska Native; Asian',\n",
       " 'P2_058N': 'White; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
       " 'P2_046N': 'American Indian and Alaska Native; Asian; Some Other Race',\n",
       " 'P2_059N': 'White; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
       " 'P2_023N': 'American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
       " 'P2_011N': 'Population of two or more races:',\n",
       " 'P2_047N': 'American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
       " 'P2_035N': 'White; American Indian and Alaska Native; Some Other Race',\n",
       " 'P2_048N': 'Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
       " 'P2_036N': 'White; Asian; Native Hawaiian and Other Pacific Islander',\n",
       " 'P2_024N': 'American Indian and Alaska Native; Some Other Race',\n",
       " 'P2_037N': 'White; Asian; Some Other Race',\n",
       " 'P2_025N': 'Asian; Native Hawaiian and Other Pacific Islander',\n",
       " 'P2_013N': 'White; Black or African American',\n",
       " 'P2_018N': 'Black or African American; American Indian and Alaska Native',\n",
       " 'P2_006N': 'Black or African American alone',\n",
       " 'P2_007N': 'American Indian and Alaska Native alone',\n",
       " 'P2_019N': 'Black or African American; Asian',\n",
       " 'P2_008N': 'Asian alone',\n",
       " 'P2_009N': 'Native Hawaiian and Other Pacific Islander alone'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef34c073-4265-4554-a057-c66f3ab627af",
   "metadata": {},
   "source": [
    "## South Orange and Maplewood Tracts in Essex County, NJ\n",
    "\n",
    "We want to take a look at data from the towns of South Orange\n",
    "and Maplewood (collectively known as SoMa) in Essex County,\n",
    "NJ. \n",
    "\n",
    "### Essex County\n",
    "\n",
    "For Essex County, we found the code `'013`' on this \n",
    "[wikipedia page](https://en.wikipedia.org/wiki/List_of_counties_in_New_Jersey)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f359e65-9a38-4f6d-97fd-e2323e8b1847",
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNTY_ESSEX_NJ = '013'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799d99b9-b3a0-42eb-86b5-f83611260159",
   "metadata": {},
   "source": [
    "### SoMa Tracts\n",
    "\n",
    "We found the tracts that make up the two towns by looking\n",
    "at \n",
    "[this map](https://www2.census.gov/geo/maps/dc10map/tract/st34_nj/c34013_essex/DC10CT_C34013_002.pdf).\n",
    "We format them as strings using the convention of\n",
    "Census API, which is a six-digit string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fff0475d-c7da-4843-8e77-0f91787ecdbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['019000',\n",
       " '019100',\n",
       " '019200',\n",
       " '019300',\n",
       " '019400',\n",
       " '019500',\n",
       " '019600',\n",
       " '019700',\n",
       " '019800',\n",
       " '019900']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracts_soma = [f\"{t:06}\" for t in range(19000, 20000, 100)]\n",
    "tracts_soma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c19c94e-2269-48a2-b02d-a0e80dda611d",
   "metadata": {},
   "source": [
    "### SoMa Data Query\n",
    "\n",
    "Now we can query the data. Lets look at the arguments to our call one by one:\n",
    "\n",
    "- `STATE_NJ` - this is the state we are interested in.\n",
    "- `YEAR`- the year we want data for. For the redistricting API, 2000, 2010, and 2020 are the three valid option.\n",
    "- `block` - the resolution of data we want. We want a row for each block in SoMa. \n",
    "- `field_names.keys()` - these are all the fields we want data for. The available fields vary by year and group, which\n",
    "   is why we made the `crd.metadata` call above to get them.\n",
    "- `county=COUNTY_ESSEX_NJ` - this is a filter. We only want data for Essex County.\n",
    "- `tract=tracts_soma` - this is a second filter saying that within the county we only want the specificed tracts.\n",
    "- `key=CENSUS_API_KEY` - our API key.\n",
    "\n",
    "The return value will be a `pd.DataFrame` containing a row for each block (the resolution we specified). In order to make\n",
    "analysis of diversity and integration at various levels of geographic aggregation easier (e.g. using the \n",
    "[divintseg](https://github.com/vengroff/divintseg) package) the identifiers of all of the nested geographies from the \n",
    "state down to the block are included in each row. In this case that means we have columns for STATE, COUNTY, TRACT, BLOCK_GROUP,\n",
    "and BLOCK. After these columns, we have one column for each of the demographic fields we asked for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bbf78ff-aed4-48af-abc9-78a8893e85fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_soma = crd.data(\n",
    "    STATE_NJ, \n",
    "    YEAR, \n",
    "    'block',\n",
    "    field_names.keys(),\n",
    "    county=COUNTY_ESSEX_NJ,\n",
    "    tract=tracts_soma,\n",
    "    key=CENSUS_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5627ee53-02ad-4114-9ebd-587eac68f76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>TRACT</th>\n",
       "      <th>BLOCK_GROUP</th>\n",
       "      <th>BLOCK</th>\n",
       "      <th>P2_070N</th>\n",
       "      <th>P2_071N</th>\n",
       "      <th>P2_073N</th>\n",
       "      <th>P2_060N</th>\n",
       "      <th>P2_030N</th>\n",
       "      <th>...</th>\n",
       "      <th>P2_024N</th>\n",
       "      <th>P2_037N</th>\n",
       "      <th>P2_025N</th>\n",
       "      <th>P2_013N</th>\n",
       "      <th>P2_018N</th>\n",
       "      <th>P2_006N</th>\n",
       "      <th>P2_007N</th>\n",
       "      <th>P2_019N</th>\n",
       "      <th>P2_008N</th>\n",
       "      <th>P2_009N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>013</td>\n",
       "      <td>019400</td>\n",
       "      <td>1</td>\n",
       "      <td>1004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>013</td>\n",
       "      <td>019400</td>\n",
       "      <td>1</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>013</td>\n",
       "      <td>019400</td>\n",
       "      <td>1</td>\n",
       "      <td>1006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>013</td>\n",
       "      <td>019400</td>\n",
       "      <td>1</td>\n",
       "      <td>1007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>013</td>\n",
       "      <td>019400</td>\n",
       "      <td>1</td>\n",
       "      <td>1008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>34</td>\n",
       "      <td>013</td>\n",
       "      <td>019900</td>\n",
       "      <td>2</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>34</td>\n",
       "      <td>013</td>\n",
       "      <td>019900</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>34</td>\n",
       "      <td>013</td>\n",
       "      <td>019900</td>\n",
       "      <td>3</td>\n",
       "      <td>3001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>34</td>\n",
       "      <td>013</td>\n",
       "      <td>019900</td>\n",
       "      <td>3</td>\n",
       "      <td>3005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>34</td>\n",
       "      <td>013</td>\n",
       "      <td>019900</td>\n",
       "      <td>3</td>\n",
       "      <td>3008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    STATE COUNTY   TRACT BLOCK_GROUP BLOCK  P2_070N  P2_071N  P2_073N  \\\n",
       "0      34    013  019400           1  1004        0        0        0   \n",
       "1      34    013  019400           1  1005        0        0        0   \n",
       "2      34    013  019400           1  1006        0        0        0   \n",
       "3      34    013  019400           1  1007        0        0        0   \n",
       "4      34    013  019400           1  1008        0        0        0   \n",
       "..    ...    ...     ...         ...   ...      ...      ...      ...   \n",
       "512    34    013  019900           2  2007        0        0        0   \n",
       "513    34    013  019900           2  2010        0        0        0   \n",
       "514    34    013  019900           3  3001        0        0        0   \n",
       "515    34    013  019900           3  3005        0        0        0   \n",
       "516    34    013  019900           3  3008        0        0        0   \n",
       "\n",
       "     P2_060N  P2_030N  ...  P2_024N  P2_037N  P2_025N  P2_013N  P2_018N  \\\n",
       "0          0        0  ...        0        0        0        1        0   \n",
       "1          0        0  ...        0        0        0        3        0   \n",
       "2          0        0  ...        0        0        0        0        0   \n",
       "3          0        0  ...        0        0        0        0        0   \n",
       "4          0        0  ...        0        0        0        0        0   \n",
       "..       ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "512        0        0  ...        0        0        0        0        0   \n",
       "513        0        0  ...        0        0        0        6        0   \n",
       "514        0        0  ...        0        0        0        0        0   \n",
       "515        0        0  ...        0        0        0        0        0   \n",
       "516        0        0  ...        0        0        0        0        0   \n",
       "\n",
       "     P2_006N  P2_007N  P2_019N  P2_008N  P2_009N  \n",
       "0          0        0        3        0        0  \n",
       "1          8        0        1        1        0  \n",
       "2          4        0        0        1        0  \n",
       "3          4        0        0        8        0  \n",
       "4          0        0        0        0        0  \n",
       "..       ...      ...      ...      ...      ...  \n",
       "512        3        0        0        6        0  \n",
       "513        3        0        0        1        0  \n",
       "514        0        0        0        0        0  \n",
       "515        1        0        0        2        0  \n",
       "516        0        0        0        1        1  \n",
       "\n",
       "[517 rows x 70 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_soma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5813271-c3ad-435e-bab8-2f956f19c337",
   "metadata": {},
   "source": [
    "## Compute Diversity and Integration\n",
    "\n",
    "Now that we have the census data telling us how many people of each group there are\n",
    "in each block of SoMa, we can calculate diversity and inclusion at the tract over\n",
    "block level. For a detailed explination of what we are actually calculating here, see\n",
    "the [README.md](https://github.com/vengroff/divintseg/blob/main/README.md) in the \n",
    "[divintseg package](https://github.com/vengroff/divintseg)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "502b2a60-6669-4b39-8227-dbbe192ed8ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diversity</th>\n",
       "      <th>integration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRACT</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>019000</th>\n",
       "      <td>0.594330</td>\n",
       "      <td>0.562676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>019100</th>\n",
       "      <td>0.692372</td>\n",
       "      <td>0.594267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>019200</th>\n",
       "      <td>0.669885</td>\n",
       "      <td>0.637017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>019300</th>\n",
       "      <td>0.656123</td>\n",
       "      <td>0.617187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>019400</th>\n",
       "      <td>0.432420</td>\n",
       "      <td>0.407238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>019500</th>\n",
       "      <td>0.500850</td>\n",
       "      <td>0.471264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>019600</th>\n",
       "      <td>0.697732</td>\n",
       "      <td>0.618226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>019700</th>\n",
       "      <td>0.623099</td>\n",
       "      <td>0.565054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>019800</th>\n",
       "      <td>0.582375</td>\n",
       "      <td>0.504864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>019900</th>\n",
       "      <td>0.442070</td>\n",
       "      <td>0.419475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        diversity  integration\n",
       "TRACT                         \n",
       "019000   0.594330     0.562676\n",
       "019100   0.692372     0.594267\n",
       "019200   0.669885     0.637017\n",
       "019300   0.656123     0.617187\n",
       "019400   0.432420     0.407238\n",
       "019500   0.500850     0.471264\n",
       "019600   0.697732     0.618226\n",
       "019700   0.623099     0.565054\n",
       "019800   0.582375     0.504864\n",
       "019900   0.442070     0.419475"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis.di(df_soma, by='TRACT', over='BLOCK', drop_non_numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e19cba-1bac-4555-a44d-853df0f94b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
